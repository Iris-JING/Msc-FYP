{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnLUKby_7RXo"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:16:30.899821Z",
     "start_time": "2018-09-05T23:16:10.554458Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2yrL2SKk7RYW"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7eb7df1ef835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdummy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\自己安装的软件\\python\\3.6\\lib\\site-packages\\xgboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\自己安装的软件\\python\\3.6\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\自己安装的软件\\python\\3.6\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\自己安装的软件\\python\\3.6\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\自己安装的软件\\python\\3.6\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV # important!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:23:06.108166Z",
     "start_time": "2018-09-04T15:23:05.974816Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "imhgTb5j7RYl"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('./drive/Msc_FYP/data/data_100.pickle')\n",
    "# items = pd.read_pickle('./drive/Msc_FYP/data/fdump_100.pickle')\n",
    "\n",
    "df = pd.read_pickle('data_100.pickle')\n",
    "items = pd.read_pickle('fdump_100.pickle')\n",
    "df = df.query('defined_target_vb200_vf3_volatility_VWAP_200 == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:23:06.874784Z",
     "start_time": "2018-09-04T15:23:06.866863Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8csH6C9KVp5X"
   },
   "outputs": [],
   "source": [
    "feats_dict3 = {'gram':[c for c in df.columns if c.startswith('gram')],\n",
    "              'pos':[c for c in df.columns if c.startswith('pos')],\n",
    "              'title_tfidf':[c for c in df.columns if c.startswith('title_tfidf')],\n",
    "              'source_bow':[c for c in df.columns if c.startswith('source_bow')],\n",
    "              'Pre_Doc2Vec': [c for c in df.columns if c.startswith('Pre_Doc2Vec')],\n",
    "              'pol_sub':[c for c in df.columns if c.startswith('polarity') | c.startswith('subje')],\n",
    "              'tfidf':[c for c in df.columns if c.startswith('tfidf')]}\n",
    "\n",
    "gram = feats_dict3['gram']\n",
    "pos = feats_dict3['pos']\n",
    "title = feats_dict3['title_tfidf']\n",
    "source = feats_dict3['source_bow']\n",
    "Doc2Vec = feats_dict3['Pre_Doc2Vec']\n",
    "pol_sub = feats_dict3['pol_sub']\n",
    "tfidf = feats_dict3['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:23:42.432714Z",
     "start_time": "2018-09-04T15:23:42.426292Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2iucbhtgupaS",
    "outputId": "b5b2a9bc-1230-40ab-febb-1be062a2dc43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3394, 971)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #(5193-3500=1693)\n",
    "\n",
    "#[:3600] [3600:4630][4630:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WmnkFXK7RfD"
   },
   "source": [
    "# Only nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqGSOSNU_w3r"
   },
   "source": [
    "## training functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:23:51.548080Z",
     "start_time": "2018-09-04T15:23:51.234382Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_1-JD6exBt9_"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "def get_data(data, feats_col, target_col):\n",
    "\n",
    "    X = data[feats_col].apply(np.float32)\n",
    "   \n",
    "    X = X.values\n",
    "    targets = ['target_{}'.format(target_col)]\n",
    "    targets_dataframe = df[targets]\n",
    "    targets_dataframe[targets] = np.where(targets_dataframe[targets]!=-1,targets_dataframe[targets],float(2))\n",
    "    y = targets_dataframe.values\n",
    "    \n",
    "    c, r = y.shape\n",
    "    y = y.reshape(c,)\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "  \n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "def cv_generator(n_cv):\n",
    "    \n",
    "    N = 2758 #4089 [0:3600] [3600:4630] [4630:]\n",
    "    \n",
    "    n_train = int(np.floor(N/(1+0.3*n_cv)))\n",
    "    n_test = int(np.floor(0.3*n_train))\n",
    "    \n",
    "    for cv_idx in range(n_cv):\n",
    "        \n",
    "        train_idx = [i for i in range(cv_idx*n_test, cv_idx*n_test +n_train)] \n",
    "        test_idx = [i for i in range(cv_idx*n_test +n_train, (cv_idx+1)*n_test +n_train)] \n",
    "        \n",
    "        yield (train_idx, test_idx)\n",
    "        \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "def AUC(y_true,y_probas):\n",
    "    \n",
    "#     print(y_probas)\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n",
    "                                      pos_label=classes[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    average_score = (roc_auc[1]+roc_auc[2])/2\n",
    "    return average_score\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "\n",
    "title_fontsize=\"small\"\n",
    "text_fontsize=\"small\"\n",
    "curves=('micro', 'macro', 'each_class')\n",
    "cmap='nipy_spectral'\n",
    "\n",
    "\n",
    "def plot_AUC(true_y,predict,title):\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    y_true = true_y\n",
    "    y_probas = predict\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "    if 'micro' not in curves and 'macro' not in curves and \\\n",
    "            'each_class' not in curves:\n",
    "        raise ValueError('Invalid argument for curves as it '\n",
    "                         'only takes \"micro\", \"macro\", or \"each_class\"')\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n",
    "                                      pos_label=classes[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "       \n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    micro_key = 'micro'\n",
    "    i = 0\n",
    "    while micro_key in fpr:\n",
    "        i += 1\n",
    "        micro_key += str(i)\n",
    "\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    if len(classes) == 2:\n",
    "        y_true = np.hstack((1 - y_true, y_true))\n",
    "\n",
    "    fpr[micro_key], tpr[micro_key], _ = roc_curve(y_true.ravel(),\n",
    "                                                  probas.ravel())\n",
    "    roc_auc[micro_key] = auc(fpr[micro_key], tpr[micro_key])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[x] for x in range(len(classes))]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(len(classes)):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= len(classes)\n",
    "\n",
    "    macro_key = 'macro'\n",
    "    i = 0\n",
    "    while macro_key in fpr:\n",
    "        i += 1\n",
    "        macro_key += str(i)\n",
    "    fpr[macro_key] = all_fpr\n",
    "    tpr[macro_key] = mean_tpr\n",
    "    roc_auc[macro_key] = auc(fpr[macro_key], tpr[macro_key])\n",
    "   \n",
    "\n",
    "    title = title\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "\n",
    "#         if 'each_class' in curves:\n",
    "    for i in range(len(classes)):\n",
    "        color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, color=color,\n",
    "                label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                ''.format(classes[i], roc_auc[i]))\n",
    "\n",
    "#         if 'micro' in curves:\n",
    "    plt.plot(fpr[micro_key], tpr[micro_key],\n",
    "            label='micro-average ROC curve '\n",
    "                  '(area = {0:0.2f})'.format(roc_auc[micro_key]),\n",
    "            color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "#         if 'macro' in curves:\n",
    "    plt.plot(fpr[macro_key], tpr[macro_key],\n",
    "            label='macro-average ROC curve '\n",
    "                  '(area = {0:0.2f})'.format(roc_auc[macro_key]),\n",
    "            color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=text_fontsize)\n",
    "    plt.ylabel('True Positive Rate', fontsize=text_fontsize)\n",
    "    plt.tick_params(labelsize=text_fontsize)\n",
    "    plt.legend(loc='lower right', fontsize=text_fontsize)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "-Suhu-NjIkbn"
   },
   "source": [
    "## single nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:16:30.915446Z",
     "start_time": "2018-09-05T23:16:23.112Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6MfvPpH0_4nV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dict3={}\n",
    "\n",
    "feats_dict3 = {'gram':[c for c in df.columns if c.startswith('gram')],\n",
    "              'pos':[c for c in df.columns if c.startswith('pos')],\n",
    "              'title_tfidf':[c for c in df.columns if c.startswith('title_tfidf')],\n",
    "              'source_bow':[c for c in df.columns if c.startswith('source_bow')],\n",
    "              'Pre_Doc2Vec': [c for c in df.columns if c.startswith('Pre_Doc2Vec')],\n",
    "              'pol_sub':[c for c in df.columns if c.startswith('polarity') | c.startswith('subje')],\n",
    "              'tfidf':[c for c in df.columns if c.startswith('tfidf')]}\n",
    "\n",
    "AUC_score = make_scorer(AUC, greater_is_better=True, needs_proba = True)\n",
    "scoring = {'AUC': AUC_score}\n",
    "\n",
    "\n",
    "target_cols = 'vb200_vf3_volatility_VWAP_200'\n",
    "i = 0\n",
    "for feats_key, feats_col in feats_dict3.items():                \n",
    "\n",
    "    i+=1\n",
    "\n",
    "    X, y = get_data(df, feats_col, target_cols)\n",
    "\n",
    "    #XGBOOST()\n",
    "    fit_params={\"early_stopping_rounds\":5, \n",
    "                \"eval_metric\" : \"mlogloss\", \n",
    "                \"eval_set\" : [(X[2758:], y[2758:])],\n",
    "                \"verbose\":5}\n",
    "    cv = cv_generator(2)\n",
    "\n",
    "    gs = GridSearchCV(XGBClassifier(objective= 'multi:softprob'),\n",
    "                      param_grid={\n",
    "                                  'learning_rate':[0.3],\n",
    "                                 },\n",
    "                      scoring= scoring,\n",
    "                      cv = cv,\n",
    "                      n_jobs=10,\n",
    "                      verbose=1,\n",
    "                      fit_params = fit_params,\n",
    "                      refit= 'AUC') #\n",
    "\n",
    "\n",
    "    gs.fit(X, y)\n",
    "    output_dict3['model_{}'.format(i)] = {'target':target_cols, 'feats':feats_key, 'GridObject':gs}\n",
    "\n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "mqx__6e97sN2"
   },
   "source": [
    "### result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T17:07:52.142819Z",
     "start_time": "2018-08-30T17:07:51.961444Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "hidden": true,
    "id": "PJ9peEDZSQbU",
    "outputId": "52000936-21d5-410c-d51c-7951687c2dff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feats</th>\n",
       "      <th>GridObject</th>\n",
       "      <th>para</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>gram</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.495994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>pos</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.480447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>title_tfidf</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.481885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>source_bow</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.483124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>Pre_Doc2Vec</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.490128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>pol_sub</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.501099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.504475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target        feats  \\\n",
       "model_1  vb200_vf3_volatility_VWAP_200         gram   \n",
       "model_2  vb200_vf3_volatility_VWAP_200          pos   \n",
       "model_3  vb200_vf3_volatility_VWAP_200  title_tfidf   \n",
       "model_4  vb200_vf3_volatility_VWAP_200   source_bow   \n",
       "model_5  vb200_vf3_volatility_VWAP_200  Pre_Doc2Vec   \n",
       "model_6  vb200_vf3_volatility_VWAP_200      pol_sub   \n",
       "model_7  vb200_vf3_volatility_VWAP_200        tfidf   \n",
       "\n",
       "                                                GridObject  \\\n",
       "model_1  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_2  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_3  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_4  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_5  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_6  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_7  GridSearchCV(cv=<generator object cv_generator...   \n",
       "\n",
       "                           para     score  \n",
       "model_1  {'learning_rate': 0.3}  0.495994  \n",
       "model_2  {'learning_rate': 0.3}  0.480447  \n",
       "model_3  {'learning_rate': 0.3}  0.481885  \n",
       "model_4  {'learning_rate': 0.3}  0.483124  \n",
       "model_5  {'learning_rate': 0.3}  0.490128  \n",
       "model_6  {'learning_rate': 0.3}  0.501099  \n",
       "model_7  {'learning_rate': 0.3}  0.504475  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3 = pd.DataFrame.from_dict(output_dict3, orient='index')\n",
    "# train['word_count'] = train['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "output_3['para']=output_3['GridObject'].apply(lambda x: x.best_params_ )\n",
    "output_3['score']=output_3['GridObject'].apply(lambda x: x.best_score_ )\n",
    "\n",
    "output_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IH97HHkn7avQ"
   },
   "source": [
    "## hyper-parameter, many nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:25:07.828898Z",
     "start_time": "2018-09-01T21:25:07.821751Z"
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "def precision(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    average_precision = {}\n",
    "    for i in range(len(classes)):\n",
    "        average_precision[i] = average_precision_score(y_true[:, i], probas[:, i])\n",
    "        \n",
    "    ave_precision = (average_precision[1]+average_precision[2])/2\n",
    "\n",
    "    return ave_precision\n",
    "    \n",
    "def recall(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    recall = {}\n",
    "    for i in range(len(classes)):\n",
    "        recall[i] = recall_score(y_true[:, i], probas[:, i].round())\n",
    "        \n",
    "    ave_recall = (recall[1]+recall[2])/2\n",
    "\n",
    "    return ave_recall\n",
    "\n",
    "\n",
    "def accuracy(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    acc = {}\n",
    "    for i in range(len(classes)):\n",
    "        acc[i] = accuracy_score(y_true[:, i], probas[:, i].round())\n",
    "        \n",
    "    ave_acc = (acc[1]+acc[2])/2\n",
    "    \n",
    "    return ave_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:16:43.910317Z",
     "start_time": "2018-09-05T23:16:43.827356Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "DlUIdlh2SnuC",
    "outputId": "4afad0c6-c30e-4e63-e206-a1558c80ce14",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(data, feats_col, target_col):\n",
    "    \n",
    "    X = data[feats_col].apply(np.float32)\n",
    "    X = X.values\n",
    "    targets = ['target_{}'.format(target_col)]\n",
    "    targets_dataframe = df[targets]\n",
    "    targets_dataframe[targets] = np.where(targets_dataframe[targets]!=-1,targets_dataframe[targets],float(2))\n",
    "    y = targets_dataframe.values\n",
    "    \n",
    "    c, r = y.shape\n",
    "    y = y.reshape(c,)\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "  \n",
    "# ++  tfidf+pol_sub+gram+Doc2Vec+source+title+pos\n",
    "feats_com = [tfidf,tfidf+pol_sub,tfidf+pol_sub+gram,\n",
    "            tfidf+pol_sub+gram+Doc2Vec+source,\n",
    "            tfidf+pol_sub+gram+Doc2Vec+source+title+pos]\n",
    "\n",
    "output_dict3={}\n",
    "\n",
    "AUC_score = make_scorer(AUC, greater_is_better=True, needs_proba = True)\n",
    "_precision_score = make_scorer(precision, greater_is_better=True, needs_proba = True)\n",
    "_recall_score = make_scorer(recall, greater_is_better=True, needs_proba = True)\n",
    "_accuracy_score = make_scorer(accuracy, greater_is_better=True, needs_proba = True)\n",
    "\n",
    "scoring = {'AUC': AUC_score,'precision':_precision_score,'recall':_recall_score,'accuracy':_accuracy_score}\n",
    "\n",
    "learning_rate = [[2.2],[2.0],[0.8],[2.6],[3.4]]\n",
    "n_estimators = [[150],[400],[350],[200],[800]]\n",
    "max_depth = [[3],[2],[3],[4],[3]]\n",
    "min_child_weight = [[3],[1],[1],[1],[1]]\n",
    "gamma = [[0.3],[0],[0.2],[0.4],[0]]\n",
    "subsample = [[0.9],[1],[1],[1],[1]]\n",
    "bytree = [[0.6],[1],[1],[1],[1]]\n",
    "reg_alpha = [[0.005],[0.001],[0],[0],[0]]\n",
    "\n",
    "\n",
    "target_cols = 'vb200_vf3_volatility_VWAP_200'\n",
    "for i in range(5):\n",
    "    \n",
    "    feature = feats_com[i]\n",
    "    X, y = get_data(df, feature, target_cols)\n",
    "    cv = cv_generator(1)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "                         objective= 'multi:softprob',\n",
    "                        )\n",
    "\n",
    "\n",
    "    gs = GridSearchCV(xgb,\n",
    "                      param_grid={\n",
    "                                  'learning_rate':learning_rate[i],\n",
    "                                  'n_estimators':n_estimators[i],\n",
    "                                  'max_depth':max_depth[i],\n",
    "                                  'min_child_weight':min_child_weight[i],\n",
    "                                  'gamma':gamma[i],\n",
    "                                  'subsample':subsample[i],\n",
    "                                  'colsample_bytree':bytree[i],\n",
    "                                  'reg_alpha':reg_alpha[i]\n",
    "                                 },\n",
    "                      scoring= scoring,\n",
    "                      cv = cv,\n",
    "                      n_jobs=10,\n",
    "                      verbose=1,\n",
    "                      refit='AUC')\n",
    "\n",
    "\n",
    "    gs.fit(X[:2758], y[:2758])\n",
    "    output_dict3['model_{}'.format(i+1)] = {'target':target_cols,'GridObject':gs}\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-7W1gUy-wEK"
   },
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:27:36.479890Z",
     "start_time": "2018-09-01T21:27:36.453993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>GridObject</th>\n",
       "      <th>para</th>\n",
       "      <th>score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'gamma': 0.3, 'learn...</td>\n",
       "      <td>0.528094</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.244065</td>\n",
       "      <td>0.297781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0, 'learning_...</td>\n",
       "      <td>0.515286</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.238381</td>\n",
       "      <td>0.296441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0.2, 'learnin...</td>\n",
       "      <td>0.515268</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.110195</td>\n",
       "      <td>0.303962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0.4, 'learnin...</td>\n",
       "      <td>0.531276</td>\n",
       "      <td>0.636792</td>\n",
       "      <td>0.269303</td>\n",
       "      <td>0.295779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>vb200_vf3_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0, 'learning_...</td>\n",
       "      <td>0.533144</td>\n",
       "      <td>0.634434</td>\n",
       "      <td>0.306972</td>\n",
       "      <td>0.299377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target  \\\n",
       "model_1  vb200_vf3_volatility_VWAP_200   \n",
       "model_2  vb200_vf3_volatility_VWAP_200   \n",
       "model_3  vb200_vf3_volatility_VWAP_200   \n",
       "model_4  vb200_vf3_volatility_VWAP_200   \n",
       "model_5  vb200_vf3_volatility_VWAP_200   \n",
       "\n",
       "                                                GridObject  \\\n",
       "model_1  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_2  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_3  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_4  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_5  GridSearchCV(cv=<generator object cv_generator...   \n",
       "\n",
       "                                                      para     score  \\\n",
       "model_1  {'colsample_bytree': 0.6, 'gamma': 0.3, 'learn...  0.528094   \n",
       "model_2  {'colsample_bytree': 1, 'gamma': 0, 'learning_...  0.515286   \n",
       "model_3  {'colsample_bytree': 1, 'gamma': 0.2, 'learnin...  0.515268   \n",
       "model_4  {'colsample_bytree': 1, 'gamma': 0.4, 'learnin...  0.531276   \n",
       "model_5  {'colsample_bytree': 1, 'gamma': 0, 'learning_...  0.533144   \n",
       "\n",
       "         Accuracy    Recall  precision  \n",
       "model_1  0.635220  0.244065   0.297781  \n",
       "model_2  0.635220  0.238381   0.296441  \n",
       "model_3  0.683962  0.110195   0.303962  \n",
       "model_4  0.636792  0.269303   0.295779  \n",
       "model_5  0.634434  0.306972   0.299377  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3 = pd.DataFrame.from_dict(output_dict3, orient='index')\n",
    "# train['word_count'] = train['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "output_3['para']=output_3['GridObject'].apply(lambda x: x.best_params_ )\n",
    "output_3['score']=output_3['GridObject'].apply(lambda x: x.best_score_ )\n",
    "output_3['Accuracy']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_accuracy'][0])\n",
    "output_3['Recall']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_recall'][0])\n",
    "output_3['precision']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_precision'][0])\n",
    "output_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:27:36.825221Z",
     "start_time": "2018-09-01T21:27:36.817550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.6, gamma=0.3, learning_rate=2.2,\n",
       "        max_delta_step=0, max_depth=3, min_child_weight=3, missing=None,\n",
       "        n_estimators=150, n_jobs=1, nthread=None,\n",
       "        objective='multi:softprob', random_state=0, reg_alpha=0.005,\n",
       "        reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "        subsample=0.9),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=2.0, max_delta_step=0,\n",
       "        max_depth=2, min_child_weight=1, missing=None, n_estimators=400,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0.001, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0.2, learning_rate=0.8, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=1, missing=None, n_estimators=350,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0.4, learning_rate=2.6, max_delta_step=0,\n",
       "        max_depth=4, min_child_weight=1, missing=None, n_estimators=200,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=3.4, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=1, missing=None, n_estimators=800,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "models = []\n",
    "for i in range(5):\n",
    "    models.append(output_3['GridObject'].iloc[i].best_estimator_)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T15:53:03.574871Z",
     "start_time": "2018-08-31T15:53:03.569886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'colsample_bytree': 0.6,\n",
       "  'gamma': 0.3,\n",
       "  'learning_rate': 2.2,\n",
       "  'max_depth': 3,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 150,\n",
       "  'reg_alpha': 0.005,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 2.0,\n",
       "  'max_depth': 2,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 400,\n",
       "  'reg_alpha': 0.001,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0.2,\n",
       "  'learning_rate': 0.8,\n",
       "  'max_depth': 3,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 350,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0.4,\n",
       "  'learning_rate': 2.6,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 200,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 3.4,\n",
       "  'max_depth': 3,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 800,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 1}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!!!!!!!!!!\n",
    "output_3['para'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1SzlXUlOBwS"
   },
   "source": [
    "### testing result -- plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:16:54.755978Z",
     "start_time": "2018-09-05T23:16:54.739381Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "E0TQfeLh-9dN",
    "outputId": "cd0a4280-62d0-4a60-f460-cfc83b891276",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     best = gs.best_estimator_\n",
    "#   print(best)\n",
    "    best = models[i]\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "    best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf3_volatility_VWAP_200'][:2758])\n",
    "#   print('AUC_{}'.format(i+1), AUC(y[-818:],best.predict_proba(X[-818:])))\n",
    "    plot_AUC(y[2758:],best.predict_proba(X[2758:]),'model{}'.format(i+1))\n",
    "#     print(best.predict_proba(X[2758:]))\n",
    "  \n",
    "#   gs.cv_results_['mean_train_AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "colab_type": "code",
    "id": "HCHN_RCw-Zev",
    "outputId": "825554b3-b0ec-430b-dc72-35dc37eb4247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      count      mean\n",
      "target_vb50_vf2_volatility_VWAP_200                  \n",
      "-1.0                                  565.0 -0.003367\n",
      " 0.0                                 4052.0 -0.000021\n",
      " 1.0                                  576.0  0.003335\n",
      "                                      count      mean\n",
      "target_vb50_vf3_volatility_VWAP_200                  \n",
      "-1.0                                  244.0 -0.004437\n",
      " 0.0                                 4719.0 -0.000021\n",
      " 1.0                                  230.0  0.004473\n",
      "                                       count      mean\n",
      "target_vb100_vf2_volatility_VWAP_200                  \n",
      "-1.0                                  1007.0 -0.003694\n",
      " 0.0                                  3201.0 -0.000003\n",
      " 1.0                                   985.0  0.003747\n",
      "                                       count      mean\n",
      "target_vb100_vf3_volatility_VWAP_200                  \n",
      "-1.0                                   539.0 -0.004896\n",
      " 0.0                                  4116.0 -0.000029\n",
      " 1.0                                   538.0  0.004820\n",
      "                                       count      mean\n",
      "target_vb200_vf2_volatility_VWAP_200                  \n",
      "-1.0                                  1401.0 -0.003951\n",
      " 0.0                                  2404.0 -0.000024\n",
      " 1.0                                  1388.0  0.004059\n",
      "                                       count      mean\n",
      "target_vb200_vf3_volatility_VWAP_200                  \n",
      "-1.0                                   971.0 -0.005301\n",
      " 0.0                                  3264.0 -0.000070\n",
      " 1.0                                   958.0  0.005427\n"
     ]
    }
   ],
   "source": [
    "for c in ['target_vb50_vf2_volatility_VWAP_200','target_vb50_vf3_volatility_VWAP_200','target_vb100_vf2_volatility_VWAP_200','target_vb100_vf3_volatility_VWAP_200','target_vb200_vf2_volatility_VWAP_200','target_vb200_vf3_volatility_VWAP_200']:\n",
    "    print(df[[c, c.replace('target', 'futureReturn')]].groupby(c).describe()[c.replace('target', 'futureReturn')][['count', 'mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKrnOjKckBzB"
   },
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:17:04.376717Z",
     "start_time": "2018-09-05T23:17:04.353296Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1925
    },
    "colab_type": "code",
    "id": "qqL2FJ-dkDsT",
    "outputId": "c9c7da8e-c2f1-4be3-fef8-79bf5427f824",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs = output_3['GridObject'].iloc[0]\n",
    "best = gs.best_estimator_\n",
    "feats = feats_com[0]\n",
    "X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "prediction_df = pd.DataFrame(best.predict_proba(X[2758:]),columns = ['idel_1','buy_1','sell_1']).reset_index()\n",
    "\n",
    "for i in range(1,5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     best = gs.best_estimator_\n",
    "    best = models[i]\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "    best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf3_volatility_VWAP_200'][:2758])\n",
    "    predictions = pd.DataFrame(best.predict_proba(X[2758:]),\n",
    "                                 columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "    \n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "# prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:30:47.631681Z",
     "start_time": "2018-09-01T21:30:47.589839Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "To3ndD22oBW9"
   },
   "outputs": [],
   "source": [
    "prediction_df.to_pickle('prediction_df_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:17:09.869844Z",
     "start_time": "2018-09-05T23:17:09.853249Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "94hOM4mrlVJ5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_score_list = []\n",
    "accuracy_list = []\n",
    "for i in range(5):\n",
    "    gs = output_3['GridObject'].iloc[i]\n",
    "    best = gs.best_estimator_\n",
    "#   print(best)\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "#   print('AUC_{}'.format(i+1), AUC(y[-818:],best.predict_proba(X[-818:])))\n",
    "    accuracy_list.append(accuracy_score(y[4150:],best.predict(X[4150:])))\n",
    "    auc_score_list.append(AUC(y[4150:],best.predict_proba(X[4150:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T09:30:15.205728Z",
     "start_time": "2018-08-29T09:30:15.201129Z"
    }
   },
   "source": [
    "## Contains Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:17:20.268479Z",
     "start_time": "2018-09-05T23:17:20.249933Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model conbinations\n",
    "from xgboost import plot_importance\n",
    "market_feats = items['all_feats'][:189]\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     model = gs.best_estimator_\n",
    "#     feats = feats_com[i]\n",
    "    model = models[i]\n",
    "    X,y = get_data(df,market_feats,'vb200_vf3_volatility_VWAP_200')\n",
    "    model.fit(X[2758:], y[2758:],sample_weight = df['sample_weights_vb200_vf3_volatility_VWAP_200'][:2758])\n",
    "    features_name = list(df[market_feats].columns.values)\n",
    "    feature_importance = list(zip(features_name, model.feature_importances_))\n",
    "    data = pd.DataFrame(feature_importance,columns=['feature','importance'])\n",
    "    data.to_csv('./Target_Two/market_importance_model{}.csv'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:17:28.227038Z",
     "start_time": "2018-09-05T23:17:28.196780Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## pick important market features\n",
    "# accuracy_list = []\n",
    "# auc_score_list = []\n",
    "# for i in range(5):\n",
    "# #     gs = output_3['GridObject'].iloc[i]\n",
    "# #     model = gs.best_estimator_\n",
    "#     model = models[i]\n",
    "#     market_feats = pd.read_csv('./Target_Two/market_importance_model{}.csv'.format(i+1))['feature'].tolist()[:20]\n",
    "#     feats = feats_com[i] + market_feats\n",
    "#     X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "#     model.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf3_volatility_VWAP_200'][:2758])\n",
    "#     y_true = y[2758:]\n",
    "#     y_probas = model.predict_proba(X[2758:])\n",
    "#     y_predict = model.predict(X[2758:])\n",
    "    \n",
    "#     plot_AUC(y_true,y_probas,'model{}'.format(i+1))\n",
    "#     accuracy_list.append(accuracy_score(y_true,y_predict))\n",
    "#     auc_score_list.append(AUC(y_true,y_probas))\n",
    "    \n",
    "#     if i == 0:\n",
    "#         prediction_df = pd.DataFrame(y_probas,\n",
    "#                                      columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "#     else:\n",
    "#         predictions =  pd.DataFrame(y_probas,\n",
    "#                                      columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "#         prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "\n",
    "# true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "# prediction_df['true_value'] = true['true_value'] #idle\n",
    "# prediction_df.to_pickle('prediction_df_market2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:17:32.920773Z",
     "start_time": "2018-09-05T23:17:32.894417Z"
    }
   },
   "outputs": [],
   "source": [
    "market_feats = items['all_feats'][:189]\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "    model = models[i]\n",
    "    feats = feats_com[i] + market_feats\n",
    "    X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "    model.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf3_volatility_VWAP_200'][:2758])\n",
    "    y_true = y[2758:]\n",
    "    y_probas = model.predict_proba(X[2758:])\n",
    "    y_predict = model.predict(X[2758:])\n",
    "    \n",
    "#     plot_AUC(y_true,y_probas,'model{}'.format(i+1))\n",
    "#     accuracy_list.append(accuracy_score(y_true,y_predict))\n",
    "#     auc_score_list.append(AUC(y_true,y_probas))\n",
    "    \n",
    "    if i == 0:\n",
    "        prediction_df = pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    else:\n",
    "        predictions =  pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "        prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "prediction_df.to_pickle('prediction_df_all2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:42:27.087862Z",
     "start_time": "2018-09-04T15:42:26.558494Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py:3141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py:3113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "feats_com = [tfidf,tfidf+pol_sub,tfidf+pol_sub+gram,\n",
    "            tfidf+pol_sub+gram+Doc2Vec+source,\n",
    "            tfidf+pol_sub+gram+Doc2Vec+source+title+pos]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stra = \"stratified\"\n",
    "feats = feats_com[4]\n",
    "X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "clf = DummyClassifier(strategy=stra, random_state=0)\n",
    "clf = clf.fit(X[:2758], y[:2758])\n",
    "y_probas = clf.predict_proba(X[2758:])\n",
    "predictions1 =  pd.DataFrame(y_probas,\n",
    "                            columns = \n",
    "                            ['idel_nlp','buy_nlp','sell_nlp'])\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "predictions1['true_value'] = true['true_value']\n",
    "predictions1.to_pickle('./Dummy/prediction_dummy_nlp1.pkl')\n",
    "\n",
    "\n",
    "feats = feats_com[1] + items['all_feats'][:189]\n",
    "X,y = get_data(df, feats, 'vb200_vf3_volatility_VWAP_200')\n",
    "clf = DummyClassifier(strategy=stra, random_state=0)\n",
    "clf = clf.fit(X[:2758], y[:2758])\n",
    "y_probas = clf.predict_proba(X[2758:])\n",
    "predictions2 =  pd.DataFrame(y_probas,\n",
    "                            columns = \n",
    "                            ['idel_all','buy_all','sell_all'])\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "predictions2['true_value'] = true['true_value']\n",
    "predictions2.to_pickle('./Dummy/prediction_dummy_all1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4WmnkFXK7RfD"
   ],
   "name": "03b2_ RUC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
