{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnLUKby_7RXo"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:14:03.026212Z",
     "start_time": "2018-09-05T23:14:03.003764Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2yrL2SKk7RYW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV # important!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:26:03.815558Z",
     "start_time": "2018-09-04T15:26:03.735556Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "imhgTb5j7RYl"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('./drive/Msc_FYP/data/data_100.pickle')\n",
    "# items = pd.read_pickle('./drive/Msc_FYP/data/fdump_100.pickle')\n",
    "df = pd.read_pickle('data_100.pickle')\n",
    "items = pd.read_pickle('fdump_100.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:26:04.757566Z",
     "start_time": "2018-09-04T15:26:04.669735Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.query('defined_target_vb100_vf2_volatility_VWAP_200 == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:26:05.256410Z",
     "start_time": "2018-09-04T15:26:05.252349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_weights_vb50_vf2_volatility_VWAP_200\n",
      "sample_weights_vb50_vf3_volatility_VWAP_200\n",
      "sample_weights_vb100_vf2_volatility_VWAP_200\n",
      "sample_weights_vb100_vf3_volatility_VWAP_200\n",
      "sample_weights_vb200_vf2_volatility_VWAP_200\n",
      "sample_weights_vb200_vf3_volatility_VWAP_200\n",
      "sample_weights_not0_vb50_vf2_volatility_VWAP_200\n",
      "sample_weights_not0_vb50_vf3_volatility_VWAP_200\n",
      "sample_weights_not0_vb100_vf2_volatility_VWAP_200\n",
      "sample_weights_not0_vb100_vf3_volatility_VWAP_200\n",
      "sample_weights_not0_vb200_vf2_volatility_VWAP_200\n",
      "sample_weights_not0_vb200_vf3_volatility_VWAP_200\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "     if c.startswith('sample_weights'):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T15:58:52.883317Z",
     "start_time": "2018-09-01T15:58:52.876197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3448, 971)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:26:15.161236Z",
     "start_time": "2018-09-04T15:26:15.150721Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8csH6C9KVp5X"
   },
   "outputs": [],
   "source": [
    "feats_dict3 = {'gram':[c for c in df.columns if c.startswith('gram')],\n",
    "              'pos':[c for c in df.columns if c.startswith('pos')],\n",
    "              'title_tfidf':[c for c in df.columns if c.startswith('title_tfidf')],\n",
    "              'source_bow':[c for c in df.columns if c.startswith('source_bow')],\n",
    "              'Pre_Doc2Vec': [c for c in df.columns if c.startswith('Pre_Doc2Vec')],\n",
    "              'pol_sub':[c for c in df.columns if c.startswith('polarity') | c.startswith('subje')],\n",
    "              'tfidf':[c for c in df.columns if c.startswith('tfidf')]}\n",
    "\n",
    "gram = feats_dict3['gram']\n",
    "pos = feats_dict3['pos']\n",
    "title = feats_dict3['title_tfidf']\n",
    "source = feats_dict3['source_bow']\n",
    "Doc2Vec = feats_dict3['Pre_Doc2Vec']\n",
    "pol_sub = feats_dict3['pol_sub']\n",
    "tfidf = feats_dict3['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:26:16.156543Z",
     "start_time": "2018-09-04T15:26:16.150704Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2iucbhtgupaS",
    "outputId": "b5b2a9bc-1230-40ab-febb-1be062a2dc43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3448, 971)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #(5193-3500=1693)\n",
    "\n",
    "#[:3600] [3600:4630][4630:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WmnkFXK7RfD"
   },
   "source": [
    "#Only nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqGSOSNU_w3r"
   },
   "source": [
    "## training functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:26:20.510102Z",
     "start_time": "2018-09-04T15:26:20.215401Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_1-JD6exBt9_"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "def get_data(data, feats_col, target_col):\n",
    "\n",
    "    X = data[feats_col].apply(np.float32)\n",
    "   \n",
    "    X = X.values\n",
    "    targets = ['target_{}'.format(target_col)]\n",
    "    targets_dataframe = df[targets]\n",
    "    targets_dataframe[targets] = np.where(targets_dataframe[targets]!=-1,targets_dataframe[targets],float(2))\n",
    "    y = targets_dataframe.values\n",
    "    \n",
    "    c, r = y.shape\n",
    "    y = y.reshape(c,)\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "  \n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "def cv_generator(n_cv):\n",
    "    \n",
    "    N = 2758 #4089 [0:3600] [3600:4630] [4630:]\n",
    "    \n",
    "    n_train = int(np.floor(N/(1+0.3*n_cv)))\n",
    "    n_test = int(np.floor(0.3*n_train))\n",
    "    \n",
    "    for cv_idx in range(n_cv):\n",
    "        \n",
    "        train_idx = [i for i in range(cv_idx*n_test, cv_idx*n_test +n_train)] \n",
    "        test_idx = [i for i in range(cv_idx*n_test +n_train, (cv_idx+1)*n_test +n_train)] \n",
    "        \n",
    "        yield (train_idx, test_idx)\n",
    "        \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "def AUC(y_true,y_probas):\n",
    "    \n",
    "#     print(y_probas)\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n",
    "                                      pos_label=classes[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    average_score = (roc_auc[1]+roc_auc[2])/2\n",
    "    return average_score\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "\n",
    "title_fontsize=\"small\"\n",
    "text_fontsize=\"small\"\n",
    "curves=('micro', 'macro', 'each_class')\n",
    "cmap='nipy_spectral'\n",
    "\n",
    "\n",
    "def plot_AUC(true_y,predict,title):\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    y_true = true_y\n",
    "    y_probas = predict\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "    if 'micro' not in curves and 'macro' not in curves and \\\n",
    "            'each_class' not in curves:\n",
    "        raise ValueError('Invalid argument for curves as it '\n",
    "                         'only takes \"micro\", \"macro\", or \"each_class\"')\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n",
    "                                      pos_label=classes[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "       \n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    micro_key = 'micro'\n",
    "    i = 0\n",
    "    while micro_key in fpr:\n",
    "        i += 1\n",
    "        micro_key += str(i)\n",
    "\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    if len(classes) == 2:\n",
    "        y_true = np.hstack((1 - y_true, y_true))\n",
    "\n",
    "    fpr[micro_key], tpr[micro_key], _ = roc_curve(y_true.ravel(),\n",
    "                                                  probas.ravel())\n",
    "    roc_auc[micro_key] = auc(fpr[micro_key], tpr[micro_key])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[x] for x in range(len(classes))]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(len(classes)):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= len(classes)\n",
    "\n",
    "    macro_key = 'macro'\n",
    "    i = 0\n",
    "    while macro_key in fpr:\n",
    "        i += 1\n",
    "        macro_key += str(i)\n",
    "    fpr[macro_key] = all_fpr\n",
    "    tpr[macro_key] = mean_tpr\n",
    "    roc_auc[macro_key] = auc(fpr[macro_key], tpr[macro_key])\n",
    "   \n",
    "\n",
    "    title = title\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "\n",
    "#         if 'each_class' in curves:\n",
    "    for i in range(len(classes)):\n",
    "        color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, color=color,\n",
    "                label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                ''.format(classes[i], roc_auc[i]))\n",
    "\n",
    "#         if 'micro' in curves:\n",
    "    plt.plot(fpr[micro_key], tpr[micro_key],\n",
    "            label='micro-average ROC curve '\n",
    "                  '(area = {0:0.2f})'.format(roc_auc[micro_key]),\n",
    "            color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "#         if 'macro' in curves:\n",
    "    plt.plot(fpr[macro_key], tpr[macro_key],\n",
    "            label='macro-average ROC curve '\n",
    "                  '(area = {0:0.2f})'.format(roc_auc[macro_key]),\n",
    "            color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=text_fontsize)\n",
    "    plt.ylabel('True Positive Rate', fontsize=text_fontsize)\n",
    "    plt.tick_params(labelsize=text_fontsize)\n",
    "    plt.legend(loc='lower right', fontsize=text_fontsize)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Suhu-NjIkbn"
   },
   "source": [
    "## single nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T20:49:14.213574Z",
     "start_time": "2018-09-01T20:49:14.209427Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "6MfvPpH0_4nV",
    "outputId": "9c23db76-5601-4215-8413-ccfe188ba97b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dict3={}\n",
    "\n",
    "feats_dict3 = {'gram':[c for c in df.columns if c.startswith('gram')],\n",
    "              'pos':[c for c in df.columns if c.startswith('pos')],\n",
    "              'title_tfidf':[c for c in df.columns if c.startswith('title_tfidf')],\n",
    "              'source_bow':[c for c in df.columns if c.startswith('source_bow')],\n",
    "              'Pre_Doc2Vec': [c for c in df.columns if c.startswith('Pre_Doc2Vec')],\n",
    "              'pol_sub':[c for c in df.columns if c.startswith('polarity') | c.startswith('subje')],\n",
    "              'tfidf':[c for c in df.columns if c.startswith('tfidf')]}\n",
    "\n",
    "AUC_score = make_scorer(AUC, greater_is_better=True, needs_proba = True)\n",
    "scoring = {'AUC': AUC_score}\n",
    "\n",
    "\n",
    "target_cols = 'vb100_vf2_volatility_VWAP_200'\n",
    "i = 0\n",
    "for feats_key, feats_col in feats_dict3.items():                \n",
    "\n",
    "    i+=1\n",
    "\n",
    "    X, y = get_data(df, feats_col, target_cols)\n",
    "\n",
    "    #XGBOOST()\n",
    "    weights = df['sample_weights_vb100_vf2_volatility_VWAP_200']\n",
    "    cv = cv_generator(2)\n",
    "    fit_params={\"early_stopping_rounds\":5, \n",
    "                \"eval_metric\" : \"mlogloss\", \n",
    "                \"eval_set\" : [(X[2758:], y[2758:])],\n",
    "                \"verbose\":5}\n",
    "\n",
    "\n",
    "    gs = GridSearchCV(XGBClassifier(objective= 'multi:softprob'),\n",
    "                      param_grid={\n",
    "                                  'learning_rate':[0.3],\n",
    "                                 },\n",
    "                      scoring= scoring,\n",
    "                      fit_params = fit_params,\n",
    "                      cv = cv,\n",
    "                      n_jobs=10,\n",
    "                      verbose=1,\n",
    "                      refit= 'AUC') #\n",
    "\n",
    "    \n",
    "    gs.fit(X, y)\n",
    "    output_dict3['model_{}'.format(i)] = {'target':target_cols, 'feats':feats_key, 'GridObject':gs}\n",
    "\n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqx__6e97sN2"
   },
   "source": [
    "### result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T16:46:25.687888Z",
     "start_time": "2018-08-30T16:46:25.658719Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XBFDCRHkxjRU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feats</th>\n",
       "      <th>GridObject</th>\n",
       "      <th>para</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>gram</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.500024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>pos</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.483609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>title_tfidf</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.511855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>source_bow</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.512144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>Pre_Doc2Vec</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.508437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>pol_sub</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.521126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.506042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target        feats  \\\n",
       "model_1  vb100_vf2_volatility_VWAP_200         gram   \n",
       "model_2  vb100_vf2_volatility_VWAP_200          pos   \n",
       "model_3  vb100_vf2_volatility_VWAP_200  title_tfidf   \n",
       "model_4  vb100_vf2_volatility_VWAP_200   source_bow   \n",
       "model_5  vb100_vf2_volatility_VWAP_200  Pre_Doc2Vec   \n",
       "model_6  vb100_vf2_volatility_VWAP_200      pol_sub   \n",
       "model_7  vb100_vf2_volatility_VWAP_200        tfidf   \n",
       "\n",
       "                                                GridObject  \\\n",
       "model_1  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_2  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_3  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_4  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_5  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_6  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_7  GridSearchCV(cv=<generator object cv_generator...   \n",
       "\n",
       "                           para     score  \n",
       "model_1  {'learning_rate': 0.3}  0.500024  \n",
       "model_2  {'learning_rate': 0.3}  0.483609  \n",
       "model_3  {'learning_rate': 0.3}  0.511855  \n",
       "model_4  {'learning_rate': 0.3}  0.512144  \n",
       "model_5  {'learning_rate': 0.3}  0.508437  \n",
       "model_6  {'learning_rate': 0.3}  0.521126  \n",
       "model_7  {'learning_rate': 0.3}  0.506042  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3 = pd.DataFrame.from_dict(output_dict3, orient='index')\n",
    "# train['word_count'] = train['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "output_3['para']=output_3['GridObject'].apply(lambda x: x.best_params_ )\n",
    "output_3['score']=output_3['GridObject'].apply(lambda x: x.best_score_ )\n",
    "\n",
    "output_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IH97HHkn7avQ"
   },
   "source": [
    "## hyper-parameter, many nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T20:53:47.742063Z",
     "start_time": "2018-09-01T20:53:47.732793Z"
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "def precision(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    average_precision = {}\n",
    "    for i in range(len(classes)):\n",
    "        average_precision[i] = average_precision_score(y_true[:, i], probas[:, i])\n",
    "        \n",
    "    ave_precision = (average_precision[1]+average_precision[2])/2\n",
    "\n",
    "    return ave_precision\n",
    "    \n",
    "def recall(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    recall_dict = {}\n",
    "    for i in range(len(classes)):\n",
    "        recall_dict[i] = recall_score(y_true[:, i], probas[:, i].round())\n",
    "        \n",
    "    ave_recall = (recall_dict[1]+recall_dict[2])/2\n",
    "\n",
    "    return ave_recall\n",
    "\n",
    "\n",
    "def accuracy(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    acc = {}\n",
    "    for i in range(len(classes)):\n",
    "        acc[i] = accuracy_score(y_true[:, i], probas[:, i].round())\n",
    "        \n",
    "    ave_acc = (acc[1]+acc[2])/2\n",
    "    \n",
    "    return ave_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:14:33.064553Z",
     "start_time": "2018-09-05T23:14:33.004034Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "colab_type": "code",
    "id": "DlUIdlh2SnuC",
    "outputId": "2e0c1a86-1d2b-4b32-de53-310fdd6c3871",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pol_sub+source+title+Doc2Vec+tfidf+gram+pos\n",
    "feats_com = [pol_sub,pol_sub+source,pol_sub+source+title,\n",
    "            pol_sub+source+title+Doc2Vec+tfidf,\n",
    "            pol_sub+source+title+Doc2Vec+tfidf+gram+pos]\n",
    "\n",
    "output_dict3={}\n",
    "\n",
    "AUC_score = make_scorer(AUC, greater_is_better=True, needs_proba = True)\n",
    "_precision_score = make_scorer(precision, greater_is_better=True, needs_proba = True)\n",
    "_recall_score = make_scorer(recall, greater_is_better=True, needs_proba = True)\n",
    "_accuracy_score = make_scorer(accuracy, greater_is_better=True, needs_proba = True)\n",
    "\n",
    "scoring = {'AUC': AUC_score,'precision':_precision_score,'recall':_recall_score,'accuracy':_accuracy_score}\n",
    "\n",
    "learning_rate = [[3.0],[2.8],[0.3],[2.6],[3.2]]\n",
    "n_estimators = [[400],[800],[100],[600],[400]]\n",
    "max_depth = [[5],[2],[5],[3],[4]]\n",
    "min_child_weight = [[1],[1],[4],[3],[2]]\n",
    "gamma = [[0.2],[0],[0],[0],[0]]\n",
    "subsample = [[0.8],[1],[1],[0.9],[0.9]]\n",
    "colsample_bytree = [[0.6],[1],[1],[0.7],[0.6]]\n",
    "reg_alpha = [[0],[0],[0.01],[0],[0]]\n",
    "             \n",
    "\n",
    "target_cols = 'vb100_vf2_volatility_VWAP_200'\n",
    "for i in range(5):\n",
    "#     print(i)\n",
    "    \n",
    "    feature = feats_com[i]\n",
    "    X, y = get_data(df, feature, target_cols)\n",
    "    cv = cv_generator(1)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "                         objective= 'multi:softprob',\n",
    "                        )\n",
    "\n",
    "\n",
    "    gs = GridSearchCV(xgb,\n",
    "                      param_grid={\n",
    "                                  'learning_rate':learning_rate[i],\n",
    "                                  'n_estimators':n_estimators[i],\n",
    "                                  'max_depth':max_depth[i],\n",
    "                                  'min_child_weight':min_child_weight[i],\n",
    "                                  'gamma':gamma[i],\n",
    "                                  'subsample':subsample[i],\n",
    "                                  'colsample_bytree':colsample_bytree[i],\n",
    "                                  'reg_alpha':reg_alpha[i]\n",
    "                                 },\n",
    "                      scoring= scoring,\n",
    "                      cv = cv,\n",
    "                      n_jobs=15,\n",
    "                      verbose=1,\n",
    "                      refit='AUC')\n",
    "\n",
    "\n",
    "    gs.fit(X[:2758], y[:2758])\n",
    "    output_dict3['model_{}'.format(i+1)] = {'target':target_cols,'GridObject':gs}\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-7W1gUy-wEK"
   },
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T20:56:16.821553Z",
     "start_time": "2018-09-01T20:56:16.796574Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "M40_9Z9yepLh",
    "outputId": "ca8752e7-34d1-47b4-de11-4b57eface267",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>GridObject</th>\n",
       "      <th>para</th>\n",
       "      <th>score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'gamma': 0.2, 'learn...</td>\n",
       "      <td>0.527431</td>\n",
       "      <td>0.523585</td>\n",
       "      <td>0.521552</td>\n",
       "      <td>0.284494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0, 'learning_...</td>\n",
       "      <td>0.530632</td>\n",
       "      <td>0.578616</td>\n",
       "      <td>0.402566</td>\n",
       "      <td>0.287371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0, 'learning_...</td>\n",
       "      <td>0.518925</td>\n",
       "      <td>0.694969</td>\n",
       "      <td>0.133053</td>\n",
       "      <td>0.293503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.534848</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.551891</td>\n",
       "      <td>0.291793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>vb100_vf2_volatility_VWAP_200</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'gamma': 0, 'learnin...</td>\n",
       "      <td>0.522684</td>\n",
       "      <td>0.587264</td>\n",
       "      <td>0.396819</td>\n",
       "      <td>0.284720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target  \\\n",
       "model_1  vb100_vf2_volatility_VWAP_200   \n",
       "model_2  vb100_vf2_volatility_VWAP_200   \n",
       "model_3  vb100_vf2_volatility_VWAP_200   \n",
       "model_4  vb100_vf2_volatility_VWAP_200   \n",
       "model_5  vb100_vf2_volatility_VWAP_200   \n",
       "\n",
       "                                                GridObject  \\\n",
       "model_1  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_2  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_3  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_4  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_5  GridSearchCV(cv=<generator object cv_generator...   \n",
       "\n",
       "                                                      para     score  \\\n",
       "model_1  {'colsample_bytree': 0.6, 'gamma': 0.2, 'learn...  0.527431   \n",
       "model_2  {'colsample_bytree': 1, 'gamma': 0, 'learning_...  0.530632   \n",
       "model_3  {'colsample_bytree': 1, 'gamma': 0, 'learning_...  0.518925   \n",
       "model_4  {'colsample_bytree': 0.7, 'gamma': 0, 'learnin...  0.534848   \n",
       "model_5  {'colsample_bytree': 0.6, 'gamma': 0, 'learnin...  0.522684   \n",
       "\n",
       "         Accuracy    Recall  precision  \n",
       "model_1  0.523585  0.521552   0.284494  \n",
       "model_2  0.578616  0.402566   0.287371  \n",
       "model_3  0.694969  0.133053   0.293503  \n",
       "model_4  0.528302  0.551891   0.291793  \n",
       "model_5  0.587264  0.396819   0.284720  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3 = pd.DataFrame.from_dict(output_dict3, orient='index')\n",
    "# train['word_count'] = train['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "output_3['para']=output_3['GridObject'].apply(lambda x: x.best_params_ )\n",
    "output_3['score']=output_3['GridObject'].apply(lambda x: x.best_score_ )\n",
    "output_3['Accuracy']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_accuracy'][0])\n",
    "output_3['Recall']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_recall'][0])\n",
    "output_3['precision']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_precision'][0])\n",
    "output_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:11:39.387116Z",
     "start_time": "2018-09-01T21:11:39.382150Z"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(5):\n",
    "    models.append(output_3['GridObject'].iloc[i].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:14:40.126135Z",
     "start_time": "2018-09-05T23:14:40.117356Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T15:53:45.805186Z",
     "start_time": "2018-08-31T15:53:45.797953Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Y5L01H51dkbV",
    "outputId": "43322e01-2664-4b3d-c294-d79d81cf4b28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'colsample_bytree': 0.6,\n",
       "  'gamma': 0.2,\n",
       "  'learning_rate': 3.0,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 400,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 0.8},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 2.8,\n",
       "  'max_depth': 2,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 800,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 0.3,\n",
       "  'max_depth': 5,\n",
       "  'min_child_weight': 4,\n",
       "  'n_estimators': 100,\n",
       "  'reg_alpha': 0.01,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 0.7,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 2.6,\n",
       "  'max_depth': 3,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 600,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.6,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 3.2,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 2,\n",
       "  'n_estimators': 400,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 0.9}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3['para'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1SzlXUlOBwS"
   },
   "source": [
    "### testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:14:47.578130Z",
     "start_time": "2018-09-05T23:14:47.552758Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "E0TQfeLh-9dN",
    "outputId": "cd0a4280-62d0-4a60-f460-cfc83b891276",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "accuracy_list = []\n",
    "auc_score_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     best = gs.best_estimator_\n",
    "    best = models[i]\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "#   print('AUC_{}'.format(i+1), AUC(y[-818:],best.predict_proba(X[-818:])))\n",
    "    y_true = y[2758:]\n",
    "    y_probas = best.predict_proba(X[2758:])\n",
    "    best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb100_vf2_volatility_VWAP_200'][:2758])\n",
    "    plot_AUC(y[2758:],best.predict_proba(X[2758:]),'model{}'.format(i+1))\n",
    "#     print(y_probas.shape)\n",
    "    recall_list.append(recall(y_true,y_probas))\n",
    "    precision_list.append(precision(y_true,y_probas))\n",
    "    accuracy_list.append(accuracy(y_true,y_probas))\n",
    "    auc_score_list.append(AUC(y_true,y_probas))\n",
    "#     print(best.predict_proba(X[4151:]))\n",
    "result_dict['AUC'] = auc_score_list\n",
    "result_dict['accuracy'] = accuracy_list\n",
    "result_dict['recall'] = recall_list\n",
    "result_dict['precision'] = precision_list \n",
    "#   gs.cv_results_['mean_train_AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T16:13:39.993597Z",
     "start_time": "2018-09-01T16:13:39.983943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508067</td>\n",
       "      <td>0.541304</td>\n",
       "      <td>0.444167</td>\n",
       "      <td>0.311367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498441</td>\n",
       "      <td>0.696377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.498001</td>\n",
       "      <td>0.650725</td>\n",
       "      <td>0.121793</td>\n",
       "      <td>0.297378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499275</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.303623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504729</td>\n",
       "      <td>0.503623</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>0.305308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC  accuracy    recall  precision\n",
       "0  0.508067  0.541304  0.444167   0.311367\n",
       "1  0.498441  0.696377  0.000000   0.303623\n",
       "2  0.498001  0.650725  0.121793   0.297378\n",
       "3  0.500000  0.499275  0.500000   0.303623\n",
       "4  0.504729  0.503623  0.505878   0.305308"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:14:54.384000Z",
     "start_time": "2018-09-05T23:14:54.362531Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1925
    },
    "colab_type": "code",
    "id": "qqL2FJ-dkDsT",
    "outputId": "c9c7da8e-c2f1-4be3-fef8-79bf5427f824",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gs = output_3['GridObject'].iloc[0]\n",
    "# best = gs.best_estimator_\n",
    "best = models[0]\n",
    "feats = feats_com[0]\n",
    "X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb100_vf2_volatility_VWAP_200'][:2758])\n",
    "prediction_df = pd.DataFrame(best.predict_proba(X[2758:]),columns = ['idel_1','buy_1','sell_1']).reset_index()\n",
    "\n",
    "for i in range(1,5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     best = gs.best_estimator_\n",
    "    best = models[i]\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "    best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb100_vf2_volatility_VWAP_200'][:2758])\n",
    "    predictions = pd.DataFrame(best.predict_proba(X[2758:]),\n",
    "                                 columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "    \n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "# prediction_df/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:18:13.448146Z",
     "start_time": "2018-09-01T21:18:13.388797Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "To3ndD22oBW9"
   },
   "outputs": [],
   "source": [
    "prediction_df.to_pickle('prediction_df_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plus Market features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:15:03.912024Z",
     "start_time": "2018-09-05T23:15:03.895434Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model conbinations\n",
    "from xgboost import plot_importance\n",
    "market_feats = items['all_feats'][:189]\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     model = gs.best_estimator_\n",
    "#     feats = feats_com[i]\n",
    "    model = models[i]\n",
    "    X,y = get_data(df,market_feats,'vb100_vf2_volatility_VWAP_200')\n",
    "    model.fit(X[2758:], y[2758:],sample_weight = df['sample_weights_vb100_vf2_volatility_VWAP_200'][:2758])\n",
    "    features_name = list(df[market_feats].columns.values)\n",
    "    feature_importance = list(zip(features_name, model.feature_importances_))\n",
    "    data = pd.DataFrame(feature_importance,columns=['feature','importance'])\n",
    "    data.to_csv('./Target_One/market_importance_model{}.csv'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:15:12.244394Z",
     "start_time": "2018-09-05T23:15:12.205353Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pick important market features\n",
    "result_dict = {}\n",
    "accuracy_list = []\n",
    "auc_score_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "for i in range(5):\n",
    "    gs = output_3['GridObject'].iloc[i]\n",
    "    model = gs.best_estimator_\n",
    "    market_feats = pd.read_csv('./Target_One/market_importance_model{}.csv'.format(i+1))['feature'].tolist()[:20]\n",
    "    feats = feats_com[i] + market_feats\n",
    "    X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "    model.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb100_vf2_volatility_VWAP_200'][:2758])\n",
    "    y_true = y[2758:]\n",
    "    y_probas = model.predict_proba(X[2758:])\n",
    "    y_predict = model.predict(X[2758:])\n",
    "    \n",
    "    plot_AUC(y_true,y_probas,'model{}'.format(i+1))\n",
    "    accuracy_list.append(accuracy(y_true,y_probas))\n",
    "    auc_score_list.append(AUC(y_true,y_probas))\n",
    "    recall_list.append(recall(y_true,y_probas))\n",
    "    precision_list.append(precision(y_true,y_probas))\n",
    "    \n",
    "    if i == 0:\n",
    "        prediction_df = pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    else:\n",
    "        predictions =  pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "        prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "prediction_df.to_pickle('prediction_df_market1.pkl')\n",
    "result_dict['AUC'] = auc_score_list\n",
    "result_dict['accuracy'] = accuracy_list\n",
    "result_dict['recall'] = recall_list\n",
    "result_dict['precision'] = precision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-01T21:19:45.892852Z",
     "start_time": "2018-09-01T21:19:45.884159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526161</td>\n",
       "      <td>0.565942</td>\n",
       "      <td>0.429107</td>\n",
       "      <td>0.317006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504590</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.379722</td>\n",
       "      <td>0.306643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.525522</td>\n",
       "      <td>0.625362</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>0.317975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520134</td>\n",
       "      <td>0.547826</td>\n",
       "      <td>0.445238</td>\n",
       "      <td>0.313160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.513367</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.517601</td>\n",
       "      <td>0.308190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC  accuracy    recall  precision\n",
       "0  0.526161  0.565942  0.429107   0.317006\n",
       "1  0.504590  0.556522  0.379722   0.306643\n",
       "2  0.525522  0.625362  0.197961   0.317975\n",
       "3  0.520134  0.547826  0.445238   0.313160\n",
       "4  0.513367  0.510870  0.517601   0.308190"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:15:19.308909Z",
     "start_time": "2018-09-05T23:15:19.282556Z"
    }
   },
   "outputs": [],
   "source": [
    "market_feats = items['all_feats'][:189]\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "    model = models[i]\n",
    "    feats = feats_com[i] + market_feats\n",
    "    X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "    model.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb100_vf2_volatility_VWAP_200'][:2758])\n",
    "    y_true = y[2758:]\n",
    "    y_probas = model.predict_proba(X[2758:])\n",
    "    y_predict = model.predict(X[2758:])\n",
    "    \n",
    "#     plot_AUC(y_true,y_probas,'model{}'.format(i+1))\n",
    "#     accuracy_list.append(accuracy_score(y_true,y_predict))\n",
    "#     auc_score_list.append(AUC(y_true,y_probas))\n",
    "    \n",
    "    if i == 0:\n",
    "        prediction_df = pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    else:\n",
    "        predictions =  pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "        prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "prediction_df.to_pickle('prediction_df_all1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T16:15:02.579710Z",
     "start_time": "2018-08-31T16:15:02.567447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_1</th>\n",
       "      <th>Target_2</th>\n",
       "      <th>Target_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[polarity, subjectivity, source_bow_f1, source...</td>\n",
       "      <td>[polarity, subjectivity, source_bow_f1, source...</td>\n",
       "      <td>[tfidf_f1, tfidf_f2, tfidf_f3, tfidf_f4, tfidf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Target_1  \\\n",
       "0  [polarity, subjectivity, source_bow_f1, source...   \n",
       "\n",
       "                                            Target_2  \\\n",
       "0  [polarity, subjectivity, source_bow_f1, source...   \n",
       "\n",
       "                                            Target_3  \n",
       "0  [tfidf_f1, tfidf_f2, tfidf_f3, tfidf_f4, tfidf...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = {}\n",
    "# market_feats1 = pd.read_csv('./Target_One/market_importance_model{}.csv'.format(1))['feature'].tolist()[:20]\n",
    "# market_feats2 = pd.read_csv('./Target_Two/market_importance_model{}.csv'.format(4))['feature'].tolist()[:20]\n",
    "# market_feats3 = pd.read_csv('./Target_Three/market_importance_model{}.csv'.format(2))['feature'].tolist()[:20]\n",
    "\n",
    "final['Target_1'] = [pol_sub + source]\n",
    "final['Target_2'] = [pol_sub+source+title+Doc2Vec+tfidf+gram+pos]\n",
    "final['Target_3'] = [tfidf+pol_sub]\n",
    "# Target_1 : source+Doc2Vec+pos\n",
    "# Target_2 : source+pos+tfidf+Doc2Vec+gram\n",
    "# Target_3 : source+tfidf+pos\n",
    "pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T13:49:22.223411Z",
     "start_time": "2018-08-30T13:49:22.192209Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('nlp_feats.npy', final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:41:01.732969Z",
     "start_time": "2018-09-04T15:41:01.265777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py:3141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py:3113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "feats_com = [pol_sub,pol_sub+source,pol_sub+source+title,\n",
    "            pol_sub+source+title+Doc2Vec+tfidf,\n",
    "            pol_sub+source+title+Doc2Vec+tfidf+gram+pos]\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stra = \"stratified\"\n",
    "feats = feats_com[3]\n",
    "X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "clf = DummyClassifier(strategy=stra, random_state=0)\n",
    "clf = clf.fit(X[:2758], y[:2758])\n",
    "y_probas = clf.predict_proba(X[2758:])\n",
    "predictions1 =  pd.DataFrame(y_probas,\n",
    "                            columns = \n",
    "                            ['idel_nlp','buy_nlp','sell_nlp'])\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "predictions1['true_value'] = true['true_value']\n",
    "predictions1.to_pickle('./Dummy/prediction_dummy_nlp1.pkl')\n",
    "\n",
    "\n",
    "feats = feats_com[1] + items['all_feats'][:189]\n",
    "X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "clf = DummyClassifier(strategy=stra, random_state=0)\n",
    "clf = clf.fit(X[:2758], y[:2758])\n",
    "y_probas = clf.predict_proba(X[2758:])\n",
    "predictions2 =  pd.DataFrame(y_probas,\n",
    "                            columns = \n",
    "                            ['idel_all','buy_all','sell_all'])\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "predictions2['true_value'] = true['true_value']\n",
    "predictions2.to_pickle('./Dummy/prediction_dummy_all1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4WmnkFXK7RfD"
   ],
   "name": "03b2_ RUC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
