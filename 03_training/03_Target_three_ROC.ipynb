{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnLUKby_7RXo"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:18:03.464691Z",
     "start_time": "2018-09-05T23:18:03.445170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2yrL2SKk7RYW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV # important!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:18:44.475702Z",
     "start_time": "2018-09-04T15:18:44.154389Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "imhgTb5j7RYl"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data_100.pickle')\n",
    "items = pd.read_pickle('fdump_100.pickle')\n",
    "df = df.query('defined_target_vb200_vf2_volatility_VWAP_200 == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:18:46.291177Z",
     "start_time": "2018-09-04T15:18:46.280472Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8csH6C9KVp5X"
   },
   "outputs": [],
   "source": [
    "feats_dict3 = {'gram':[c for c in df.columns if c.startswith('gram')],\n",
    "              'pos':[c for c in df.columns if c.startswith('pos')],\n",
    "              'title_tfidf':[c for c in df.columns if c.startswith('title_tfidf')],\n",
    "              'source_bow':[c for c in df.columns if c.startswith('source_bow')],\n",
    "              'Pre_Doc2Vec': [c for c in df.columns if c.startswith('Pre_Doc2Vec')],\n",
    "              'pol_sub':[c for c in df.columns if c.startswith('polarity') | c.startswith('subje')],\n",
    "              'tfidf':[c for c in df.columns if c.startswith('tfidf')]}\n",
    "\n",
    "gram = feats_dict3['gram']\n",
    "pos = feats_dict3['pos']\n",
    "title = feats_dict3['title_tfidf']\n",
    "source = feats_dict3['source_bow']\n",
    "Doc2Vec = feats_dict3['Pre_Doc2Vec']\n",
    "pol_sub = feats_dict3['pol_sub']\n",
    "tfidf = feats_dict3['tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:18:49.380278Z",
     "start_time": "2018-09-04T15:18:49.371972Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2iucbhtgupaS",
    "outputId": "b5b2a9bc-1230-40ab-febb-1be062a2dc43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3430, 971)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #(5193-3500=1693)\n",
    "\n",
    "#[:3600] [3600:4630][4630:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WmnkFXK7RfD"
   },
   "source": [
    "#Only nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqGSOSNU_w3r"
   },
   "source": [
    "## training functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:20:07.664964Z",
     "start_time": "2018-09-04T15:20:07.370568Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_1-JD6exBt9_"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------\n",
    "def get_data(data, feats_col, target_col):\n",
    "\n",
    "    X = data[feats_col].apply(np.float32)\n",
    "   \n",
    "    X = X.values\n",
    "    targets = ['target_{}'.format(target_col)]\n",
    "    targets_dataframe = df[targets]\n",
    "    targets_dataframe[targets] = np.where(targets_dataframe[targets]!=-1,targets_dataframe[targets],float(2))\n",
    "    y = targets_dataframe.values\n",
    "    \n",
    "    c, r = y.shape\n",
    "    y = y.reshape(c,)\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "  \n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "def cv_generator(n_cv):\n",
    "    \n",
    "    N = 2758 #4089 [0:3600] [3600:4630] [4630:]\n",
    "    \n",
    "    n_train = int(np.floor(N/(1+0.3*n_cv)))\n",
    "    n_test = int(np.floor(0.3*n_train))\n",
    "    \n",
    "    for cv_idx in range(n_cv):\n",
    "        \n",
    "        train_idx = [i for i in range(cv_idx*n_test, cv_idx*n_test +n_train)] \n",
    "        test_idx = [i for i in range(cv_idx*n_test +n_train, (cv_idx+1)*n_test +n_train)] \n",
    "        \n",
    "        yield (train_idx, test_idx)\n",
    "        \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "def AUC(y_true,y_probas):\n",
    "    \n",
    "#     print(y_probas)\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n",
    "                                      pos_label=classes[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    average_score = (roc_auc[1]+roc_auc[2])/2\n",
    "    return average_score\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "\n",
    "title_fontsize=\"small\"\n",
    "text_fontsize=\"small\"\n",
    "curves=('micro', 'macro', 'each_class')\n",
    "cmap='nipy_spectral'\n",
    "\n",
    "\n",
    "def plot_AUC(true_y,predict,title):\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    y_true = true_y\n",
    "    y_probas = predict\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "\n",
    "    if 'micro' not in curves and 'macro' not in curves and \\\n",
    "            'each_class' not in curves:\n",
    "        raise ValueError('Invalid argument for curves as it '\n",
    "                         'only takes \"micro\", \"macro\", or \"each_class\"')\n",
    "\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n",
    "                                      pos_label=classes[i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "       \n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    micro_key = 'micro'\n",
    "    i = 0\n",
    "    while micro_key in fpr:\n",
    "        i += 1\n",
    "        micro_key += str(i)\n",
    "\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    if len(classes) == 2:\n",
    "        y_true = np.hstack((1 - y_true, y_true))\n",
    "\n",
    "    fpr[micro_key], tpr[micro_key], _ = roc_curve(y_true.ravel(),\n",
    "                                                  probas.ravel())\n",
    "    roc_auc[micro_key] = auc(fpr[micro_key], tpr[micro_key])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[x] for x in range(len(classes))]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(len(classes)):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= len(classes)\n",
    "\n",
    "    macro_key = 'macro'\n",
    "    i = 0\n",
    "    while macro_key in fpr:\n",
    "        i += 1\n",
    "        macro_key += str(i)\n",
    "    fpr[macro_key] = all_fpr\n",
    "    tpr[macro_key] = mean_tpr\n",
    "    roc_auc[macro_key] = auc(fpr[macro_key], tpr[macro_key])\n",
    "   \n",
    "\n",
    "    title = title\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "\n",
    "#         if 'each_class' in curves:\n",
    "    for i in range(len(classes)):\n",
    "        color = plt.cm.get_cmap(cmap)(float(i) / len(classes))\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, color=color,\n",
    "                label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                ''.format(classes[i], roc_auc[i]))\n",
    "\n",
    "#         if 'micro' in curves:\n",
    "    plt.plot(fpr[micro_key], tpr[micro_key],\n",
    "            label='micro-average ROC curve '\n",
    "                  '(area = {0:0.2f})'.format(roc_auc[micro_key]),\n",
    "            color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "#         if 'macro' in curves:\n",
    "    plt.plot(fpr[macro_key], tpr[macro_key],\n",
    "            label='macro-average ROC curve '\n",
    "                  '(area = {0:0.2f})'.format(roc_auc[macro_key]),\n",
    "            color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=text_fontsize)\n",
    "    plt.ylabel('True Positive Rate', fontsize=text_fontsize)\n",
    "    plt.tick_params(labelsize=text_fontsize)\n",
    "    plt.legend(loc='lower right', fontsize=text_fontsize)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#----------------------------------------\n",
    "def precision(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    average_precision = {}\n",
    "    for i in range(len(classes)):\n",
    "        average_precision[i] = average_precision_score(y_true[:, i], probas[:, i])\n",
    "        \n",
    "    ave_precision = (average_precision[1]+average_precision[2])/2\n",
    "\n",
    "    return ave_precision\n",
    "    \n",
    "def recall(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    recall = {}\n",
    "    for i in range(len(classes)):\n",
    "        recall[i] = recall_score(y_true[:, i], probas[:, i].round())\n",
    "        \n",
    "    ave_recall = (recall[1]+recall[2])/2\n",
    "\n",
    "    return ave_recall\n",
    "\n",
    "\n",
    "def accuracy(y_true,y_probas):\n",
    "    y_true = np.array(y_true)\n",
    "    y_probas = np.array(y_probas)\n",
    "    classes = np.unique(y_true)\n",
    "    probas = y_probas\n",
    "    y_true = label_binarize(y_true, classes=classes)\n",
    "    \n",
    "    acc = {}\n",
    "    for i in range(len(classes)):\n",
    "        acc[i] = accuracy_score(y_true[:, i], probas[:, i].round())\n",
    "        \n",
    "    ave_acc = (acc[1]+acc[2])/2\n",
    "    \n",
    "    return ave_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Suhu-NjIkbn"
   },
   "source": [
    "## single nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:18:17.176954Z",
     "start_time": "2018-09-05T23:18:17.132056Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6943
    },
    "colab_type": "code",
    "id": "6MfvPpH0_4nV",
    "outputId": "d2389a40-c856-43a9-bcfb-ab1679edb86c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dict3={}\n",
    "\n",
    "feats_dict3 = {'gram':[c for c in df.columns if c.startswith('gram')],\n",
    "              'pos':[c for c in df.columns if c.startswith('pos')],\n",
    "              'title_tfidf':[c for c in df.columns if c.startswith('title_tfidf')],\n",
    "              'source_bow':[c for c in df.columns if c.startswith('source_bow')],\n",
    "              'Pre_Doc2Vec': [c for c in df.columns if c.startswith('Pre_Doc2Vec')],\n",
    "              'pol_sub':[c for c in df.columns if c.startswith('polarity') | c.startswith('subje')],\n",
    "              'tfidf':[c for c in df.columns if c.startswith('tfidf')]}\n",
    "\n",
    "AUC_score = make_scorer(AUC, greater_is_better=True, needs_proba = True)\n",
    "scoring = {'AUC': AUC_score}\n",
    "\n",
    "\n",
    "target_cols = 'vb200_vf2_volatility_VWAP_200'\n",
    "i = 0\n",
    "for feats_key, feats_col in feats_dict3.items():                \n",
    "\n",
    "    i+=1\n",
    "\n",
    "    X, y = get_data(df, feats_col, target_cols)\n",
    "\n",
    "    #XGBOOST()\n",
    "\n",
    "    cv = cv_generator(2)\n",
    "#     fit_params={\"early_stopping_rounds\":5, \n",
    "#                 \"eval_metric\" : \"mlogloss\", \n",
    "#                 \"eval_set\" : [(X[2758:], y[2758:])],\n",
    "#                 \"verbose\":5}\n",
    "\n",
    "    gs = GridSearchCV(XGBClassifier(objective= 'multi:softprob'),\n",
    "                      param_grid={\n",
    "                                  'learning_rate':[0.3],\n",
    "                                 },\n",
    "                      scoring= scoring,\n",
    "#                       fit_params = fit_params,\n",
    "                      cv = cv,\n",
    "                      n_jobs=10,\n",
    "                      verbose=1,\n",
    "                      refit= 'AUC') #\n",
    "\n",
    "\n",
    "    gs.fit(X, y)\n",
    "    output_dict3['model_{}'.format(i)] = {'target':target_cols, 'feats':feats_key, 'GridObject':gs}\n",
    "\n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqx__6e97sN2"
   },
   "source": [
    "### result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T19:17:53.543211Z",
     "start_time": "2018-08-30T19:17:53.244148Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "PJ9peEDZSQbU",
    "outputId": "7adcc7d0-983e-4787-af24-008c8bd721f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feats</th>\n",
       "      <th>GridObject</th>\n",
       "      <th>para</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>gram</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.495657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>pos</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.496523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>title_tfidf</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.488169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>source_bow</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.501416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>Pre_Doc2Vec</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.491428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>pol_sub</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.513597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>vb200_vf2_volatility_VWAP_200</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'learning_rate': 0.3}</td>\n",
       "      <td>0.516747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target        feats  \\\n",
       "model_1  vb200_vf2_volatility_VWAP_200         gram   \n",
       "model_2  vb200_vf2_volatility_VWAP_200          pos   \n",
       "model_3  vb200_vf2_volatility_VWAP_200  title_tfidf   \n",
       "model_4  vb200_vf2_volatility_VWAP_200   source_bow   \n",
       "model_5  vb200_vf2_volatility_VWAP_200  Pre_Doc2Vec   \n",
       "model_6  vb200_vf2_volatility_VWAP_200      pol_sub   \n",
       "model_7  vb200_vf2_volatility_VWAP_200        tfidf   \n",
       "\n",
       "                                                GridObject  \\\n",
       "model_1  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_2  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_3  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_4  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_5  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_6  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_7  GridSearchCV(cv=<generator object cv_generator...   \n",
       "\n",
       "                           para     score  \n",
       "model_1  {'learning_rate': 0.3}  0.495657  \n",
       "model_2  {'learning_rate': 0.3}  0.496523  \n",
       "model_3  {'learning_rate': 0.3}  0.488169  \n",
       "model_4  {'learning_rate': 0.3}  0.501416  \n",
       "model_5  {'learning_rate': 0.3}  0.491428  \n",
       "model_6  {'learning_rate': 0.3}  0.513597  \n",
       "model_7  {'learning_rate': 0.3}  0.516747  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3 = pd.DataFrame.from_dict(output_dict3, orient='index')\n",
    "# train['word_count'] = train['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "output_3['para']=output_3['GridObject'].apply(lambda x: x.best_params_ )\n",
    "output_3['score']=output_3['GridObject'].apply(lambda x: x.best_score_ )\n",
    "\n",
    "output_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IH97HHkn7avQ"
   },
   "source": [
    "## hyper-parameter, many nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:18:34.018376Z",
     "start_time": "2018-09-05T23:18:33.953962Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1208
    },
    "colab_type": "code",
    "id": "DlUIdlh2SnuC",
    "outputId": "1a0d526f-0eec-49e3-d9e6-3173053bafcd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tfidf+pol_sub+source+pos+gram+Doc2Vec+title\n",
    "feats_com = [tfidf,\n",
    "             tfidf+pol_sub,\n",
    "             tfidf+pol_sub+source,\n",
    "             tfidf+pol_sub+source+pos+gram,\n",
    "             tfidf+pol_sub+source+pos+gram+Doc2Vec+title]\n",
    "\n",
    "output_dict3={}\n",
    "\n",
    "AUC_score = make_scorer(AUC, greater_is_better=True, needs_proba = True)\n",
    "_precision_score = make_scorer(precision, greater_is_better=True, needs_proba = True)\n",
    "_recall_score = make_scorer(recall, greater_is_better=True, needs_proba = True)\n",
    "_accuracy_score = make_scorer(accuracy, greater_is_better=True, needs_proba = True)\n",
    "\n",
    "scoring = {'AUC': AUC_score,'precision':_precision_score,'recall':_recall_score,'accuracy':_accuracy_score}\n",
    "\n",
    "learning_rate = [[1.8],[1.0],[1.8],[2.4],[1.6]]\n",
    "n_estimators = [[1000],[600],[1150],[1200],[850]]\n",
    "max_depth = [[4],[7],[4],[4],[3]]\n",
    "min_child_weight = [[2],[3],[2],[1],[5]]\n",
    "gamma = [[0],[0],[0.2],[0.1],[0.2]]\n",
    "subsample = [[1],[1],[0.9],[0.6],[1]]\n",
    "colsample_bytree = [[1],[1],[1],[0.6],[1]]\n",
    "reg_alpha = [[0],[1e-5],[0],[0],[0]]\n",
    "\n",
    "target_cols = 'vb200_vf2_volatility_VWAP_200'\n",
    "for i in range(5):\n",
    "#     print(i)\n",
    "    \n",
    "    feature = feats_com[i]\n",
    "    X, y = get_data(df, feature, target_cols)\n",
    "    cv = cv_generator(1)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "                         objective= 'multi:softprob',\n",
    "                        )\n",
    "\n",
    "#     fit_params={\"early_stopping_rounds\":5, \n",
    "#                 \"eval_metric\" : \"mlogloss\", \n",
    "#                 \"eval_set\" : [(X[3370:4150,:], y[3370:4150])],\n",
    "#                 \"verbose\":5}\n",
    "    \n",
    "    gs = GridSearchCV(xgb,\n",
    "                      param_grid={\n",
    "                                  'learning_rate':learning_rate[i],\n",
    "                                  'n_estimators':n_estimators[i],\n",
    "                                  'max_depth':max_depth[i],\n",
    "                                  'min_child_weight':min_child_weight[i],\n",
    "                                  'gamma':gamma[i],\n",
    "                                  'subsample':subsample[i],\n",
    "                                  'colsample_bytree':colsample_bytree[i],\n",
    "                                  'reg_alpha':reg_alpha[i]\n",
    "                                 },\n",
    "                      scoring= scoring,\n",
    "                      cv = cv,\n",
    "                      n_jobs=10,\n",
    "                      verbose=1,\n",
    "#                       fit_params = fit_params,\n",
    "                      refit='AUC')\n",
    "\n",
    "\n",
    "    gs.fit(X[:2758], y[:2758])\n",
    "    output_dict3['model_{}'.format(i+1)] = {'GridObject':gs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-7W1gUy-wEK"
   },
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T09:28:23.733831Z",
     "start_time": "2018-09-02T09:28:23.698083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GridObject</th>\n",
       "      <th>para</th>\n",
       "      <th>score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0, 'learning_...</td>\n",
       "      <td>0.560721</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.442489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0, 'learning_...</td>\n",
       "      <td>0.563082</td>\n",
       "      <td>0.569969</td>\n",
       "      <td>0.428526</td>\n",
       "      <td>0.454649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0.2, 'learnin...</td>\n",
       "      <td>0.510453</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.390865</td>\n",
       "      <td>0.406705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 0.6, 'gamma': 0.1, 'learn...</td>\n",
       "      <td>0.543298</td>\n",
       "      <td>0.563679</td>\n",
       "      <td>0.438141</td>\n",
       "      <td>0.417416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>GridSearchCV(cv=&lt;generator object cv_generator...</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0.2, 'learnin...</td>\n",
       "      <td>0.528495</td>\n",
       "      <td>0.551887</td>\n",
       "      <td>0.452885</td>\n",
       "      <td>0.427123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                GridObject  \\\n",
       "model_1  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_2  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_3  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_4  GridSearchCV(cv=<generator object cv_generator...   \n",
       "model_5  GridSearchCV(cv=<generator object cv_generator...   \n",
       "\n",
       "                                                      para     score  \\\n",
       "model_1  {'colsample_bytree': 1, 'gamma': 0, 'learning_...  0.560721   \n",
       "model_2  {'colsample_bytree': 1, 'gamma': 0, 'learning_...  0.563082   \n",
       "model_3  {'colsample_bytree': 1, 'gamma': 0.2, 'learnin...  0.510453   \n",
       "model_4  {'colsample_bytree': 0.6, 'gamma': 0.1, 'learn...  0.543298   \n",
       "model_5  {'colsample_bytree': 1, 'gamma': 0.2, 'learnin...  0.528495   \n",
       "\n",
       "         Accuracy    Recall  precision  \n",
       "model_1  0.583333  0.404167   0.442489  \n",
       "model_2  0.569969  0.428526   0.454649  \n",
       "model_3  0.556604  0.390865   0.406705  \n",
       "model_4  0.563679  0.438141   0.417416  \n",
       "model_5  0.551887  0.452885   0.427123  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3 = pd.DataFrame.from_dict(output_dict3, orient='index')\n",
    "# train['word_count'] = train['content'].apply(lambda x: len(str(x).split(\" \")))\n",
    "output_3['para']=output_3['GridObject'].apply(lambda x: x.best_params_ )\n",
    "output_3['score']=output_3['GridObject'].apply(lambda x: x.best_score_ )\n",
    "output_3['Accuracy']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_accuracy'][0])\n",
    "output_3['Recall']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_recall'][0])\n",
    "output_3['precision']=output_3['GridObject'].apply(lambda x: x.cv_results_['mean_test_precision'][0])\n",
    "output_3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T09:28:24.065686Z",
     "start_time": "2018-09-02T09:28:24.059558Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=1.8, max_delta_step=0,\n",
       "        max_depth=4, min_child_weight=2, missing=None, n_estimators=1000,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0, learning_rate=1.0, max_delta_step=0,\n",
       "        max_depth=7, min_child_weight=3, missing=None, n_estimators=600,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0.2, learning_rate=1.8, max_delta_step=0,\n",
       "        max_depth=4, min_child_weight=2, missing=None, n_estimators=1150,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=0.9),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.6, gamma=0.1, learning_rate=2.4,\n",
       "        max_delta_step=0, max_depth=4, min_child_weight=1, missing=None,\n",
       "        n_estimators=1200, n_jobs=1, nthread=None,\n",
       "        objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "        reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "        subsample=0.6),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1, gamma=0.2, learning_rate=1.6, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=5, missing=None, n_estimators=850,\n",
       "        n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "        silent=True, subsample=1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "models = []\n",
    "for i in range(5):\n",
    "    models.append(output_3['GridObject'].iloc[i].best_estimator_)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-30T20:56:54.035Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Y5L01H51dkbV",
    "outputId": "7836470b-a3b1-4695-c83c-88faf96cabf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'colsample_bytree': 1,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 1.8,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 2,\n",
       "  'n_estimators': 1000,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 1.0,\n",
       "  'max_depth': 7,\n",
       "  'min_child_weight': 3,\n",
       "  'n_estimators': 600,\n",
       "  'reg_alpha': 1e-05,\n",
       "  'subsample': 1},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0.2,\n",
       "  'learning_rate': 1.8,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 2,\n",
       "  'n_estimators': 1150,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 0.9},\n",
       " {'colsample_bytree': 0.6,\n",
       "  'gamma': 0.1,\n",
       "  'learning_rate': 2.4,\n",
       "  'max_depth': 4,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 1200,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 0.6},\n",
       " {'colsample_bytree': 1,\n",
       "  'gamma': 0.2,\n",
       "  'learning_rate': 1.6,\n",
       "  'max_depth': 3,\n",
       "  'min_child_weight': 5,\n",
       "  'n_estimators': 850,\n",
       "  'reg_alpha': 0,\n",
       "  'subsample': 1}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_3['para'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1SzlXUlOBwS"
   },
   "source": [
    "### testing result -- plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:18:48.842338Z",
     "start_time": "2018-09-05T23:18:48.825749Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2099
    },
    "colab_type": "code",
    "id": "sYA44gN6DDMu",
    "outputId": "27c65261-0410-4171-dbb3-62ec63b789ff"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     best = gs.best_estimator_\n",
    "#   print(best)\n",
    "    best = models[i]\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "    best.fit(X[2758],y[:2758],sample_weight = df['sample_weights_vb200_vf2_volatility_VWAP_200'][:2758])\n",
    "#   print('AUC_{}'.format(i+1), AUC(y[-818:],best.predict_proba(X[-818:])))\n",
    "    plot_AUC(y[2758:],best.predict_proba(X[2758:]),'model{}'.format(i+1))\n",
    "#     print(best.predict_proba(X[4151:]))\n",
    "  \n",
    "#   gs.cv_results_['mean_train_AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "colab_type": "code",
    "id": "HCHN_RCw-Zev",
    "outputId": "825554b3-b0ec-430b-dc72-35dc37eb4247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      count      mean\n",
      "target_vb50_vf2_volatility_VWAP_200                  \n",
      "-1.0                                  565.0 -0.003367\n",
      " 0.0                                 4052.0 -0.000021\n",
      " 1.0                                  576.0  0.003335\n",
      "                                      count      mean\n",
      "target_vb50_vf3_volatility_VWAP_200                  \n",
      "-1.0                                  244.0 -0.004437\n",
      " 0.0                                 4719.0 -0.000021\n",
      " 1.0                                  230.0  0.004473\n",
      "                                       count      mean\n",
      "target_vb100_vf2_volatility_VWAP_200                  \n",
      "-1.0                                  1007.0 -0.003694\n",
      " 0.0                                  3201.0 -0.000003\n",
      " 1.0                                   985.0  0.003747\n",
      "                                       count      mean\n",
      "target_vb100_vf3_volatility_VWAP_200                  \n",
      "-1.0                                   539.0 -0.004896\n",
      " 0.0                                  4116.0 -0.000029\n",
      " 1.0                                   538.0  0.004820\n",
      "                                       count      mean\n",
      "target_vb200_vf2_volatility_VWAP_200                  \n",
      "-1.0                                  1401.0 -0.003951\n",
      " 0.0                                  2404.0 -0.000024\n",
      " 1.0                                  1388.0  0.004059\n",
      "                                       count      mean\n",
      "target_vb200_vf3_volatility_VWAP_200                  \n",
      "-1.0                                   971.0 -0.005301\n",
      " 0.0                                  3264.0 -0.000070\n",
      " 1.0                                   958.0  0.005427\n"
     ]
    }
   ],
   "source": [
    "for c in ['target_vb50_vf2_volatility_VWAP_200','target_vb50_vf3_volatility_VWAP_200','target_vb100_vf2_volatility_VWAP_200','target_vb100_vf3_volatility_VWAP_200','target_vb200_vf2_volatility_VWAP_200','target_vb200_vf3_volatility_VWAP_200']:\n",
    "    print(df[[c, c.replace('target', 'futureReturn')]].groupby(c).describe()[c.replace('target', 'futureReturn')][['count', 'mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKrnOjKckBzB"
   },
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:18:56.181116Z",
     "start_time": "2018-09-05T23:18:56.157689Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qqL2FJ-dkDsT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gs = output_3['GridObject'].iloc[0]\n",
    "# best = gs.best_estimator_\n",
    "best = models[0]\n",
    "feats = feats_com[0]\n",
    "X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf2_volatility_VWAP_200'][:2758])\n",
    "prediction_df = pd.DataFrame(best.predict_proba(X[2758:]),columns = ['idel_1','buy_1','sell_1']).reset_index()\n",
    "\n",
    "for i in range(1,5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "#     best = gs.best_estimator_\n",
    "    best = models[i]\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb100_vf2_volatility_VWAP_200')\n",
    "    best.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf2_volatility_VWAP_200'][:2758])\n",
    "    \n",
    "    predictions = pd.DataFrame(best.predict_proba(X[2758:]),\n",
    "                                 columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "    \n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-02T18:08:57.428145Z",
     "start_time": "2018-09-02T18:08:57.389945Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "To3ndD22oBW9"
   },
   "outputs": [],
   "source": [
    "prediction_df.to_pickle('prediction_df_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQC2Ww8epOl4"
   },
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:19:01.353103Z",
     "start_time": "2018-09-05T23:19:01.335542Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "94hOM4mrlVJ5",
    "outputId": "d642106a-24c6-4e1a-d659-b61a6cacb60e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_score_list = []\n",
    "accuracy_list = []\n",
    "for i in range(5):\n",
    "    gs = output_3['GridObject'].iloc[i]\n",
    "    best = gs.best_estimator_\n",
    "#   print(best)\n",
    "    feats = feats_com[i]\n",
    "    X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "#   print('AUC_{}'.format(i+1), AUC(y[-818:],best.predict_proba(X[-818:])))\n",
    "    accuracy_list.append(accuracy_score(y[4150:],best.predict(X[4150:])))\n",
    "    auc_score_list.append(AUC(y[4150:],best.predict_proba(X[4150:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lU9mAJLLL8O3",
    "outputId": "b9ef5c7c-3b68-4e3a-f3bb-422c6212fe62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6776208790885867, 0.6441968294488791, 0.6013745535554913, 0.6208417274768036, 0.6457366367256873]\n",
      "[0.5052732502396932, 0.46308724832214765, 0.4573346116970278, 0.473633748801534, 0.47555129434324067]\n"
     ]
    }
   ],
   "source": [
    "print(auc_score_list)\n",
    "print(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZNydHO7eprxw"
   },
   "source": [
    "# Contains market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:19:09.230651Z",
     "start_time": "2018-09-05T23:19:09.214064Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1394
    },
    "colab_type": "code",
    "id": "fl3QhMZPptxy",
    "outputId": "8cdf337d-9f73-4fa8-b230-f6f7a402478d"
   },
   "outputs": [],
   "source": [
    "## Model conbinations\n",
    "from xgboost import plot_importance\n",
    "market_feats = items['all_feats'][:189]\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "    model = models[i]\n",
    "#     feats = feats_com[i]\n",
    "    X,y = get_data(df,market_feats,'vb200_vf2_volatility_VWAP_200')\n",
    "    model.fit(X[2758:], y[2758:],sample_weight = df['sample_weights_vb200_vf2_volatility_VWAP_200'][:2758])\n",
    "    features_name = list(df[market_feats].columns.values)\n",
    "    feature_importance = list(zip(features_name, model.feature_importances_))\n",
    "    data = pd.DataFrame(feature_importance,columns=['feature','importance'])\n",
    "    data.to_csv('./Target_Three/market_importance_model{}.csv'.format(i+1))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:19:15.954532Z",
     "start_time": "2018-09-05T23:19:15.927204Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914
    },
    "colab_type": "code",
    "id": "n-RpNFaRqFc3",
    "outputId": "0a3889f4-6f40-44ac-d270-53a3855e5817",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pick important market features\n",
    "# accuracy_list = []\n",
    "# auc_score_list = []\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "    model = models[i]\n",
    "    market_feats = pd.read_csv('./Target_Three/market_importance_model{}.csv'.format(i+1))['feature'].tolist()[:20]\n",
    "    feats = feats_com[i] + market_feats\n",
    "    X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "    model.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf2_volatility_VWAP_200'][:2758])\n",
    "    y_true = y[2758:]\n",
    "    y_probas = model.predict_proba(X[2758:])\n",
    "    y_predict = model.predict(X[2758:])\n",
    "    \n",
    "#     plot_AUC(y_true,y_probas,'model{}'.format(i+1))\n",
    "#     accuracy_list.append(accuracy_score(y_true,y_predict))\n",
    "#     auc_score_list.append(AUC(y_true,y_probas))\n",
    "    \n",
    "    if i == 0:\n",
    "        prediction_df = pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    else:\n",
    "        predictions =  pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "        prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "prediction_df.to_pickle('prediction_df_market3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T23:19:21.788275Z",
     "start_time": "2018-09-05T23:19:21.761921Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "market_feats = items['all_feats'][:189]\n",
    "for i in range(5):\n",
    "#     gs = output_3['GridObject'].iloc[i]\n",
    "    model = models[i]\n",
    "    feats = feats_com[i] + market_feats\n",
    "    X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "    model.fit(X[:2758],y[:2758],sample_weight = df['sample_weights_vb200_vf2_volatility_VWAP_200'][:2758])\n",
    "    y_true = y[2758:]\n",
    "    y_probas = model.predict_proba(X[2758:])\n",
    "    y_predict = model.predict(X[2758:])\n",
    "    \n",
    "#     plot_AUC(y_true,y_probas,'model{}'.format(i+1))\n",
    "#     accuracy_list.append(accuracy_score(y_true,y_predict))\n",
    "#     auc_score_list.append(AUC(y_true,y_probas))\n",
    "    \n",
    "    if i == 0:\n",
    "        prediction_df = pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "    else:\n",
    "        predictions =  pd.DataFrame(y_probas,\n",
    "                                     columns = ['idel_{}'.format(i+1),'buy_{}'.format(i+1),'sell_{}'.format(i+1)])\n",
    "        prediction_df = pd.merge(prediction_df,predictions,left_index=True,right_index= True)\n",
    "\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "prediction_df['true_value'] = true['true_value'] #idle\n",
    "prediction_df.to_pickle('prediction_df_all3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T15:44:42.818436Z",
     "start_time": "2018-09-04T15:44:42.420436Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py:3141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py:3113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "feats_com = [tfidf,\n",
    "             tfidf+pol_sub,\n",
    "             tfidf+pol_sub+source,\n",
    "             tfidf+pol_sub+source+pos+gram,\n",
    "             tfidf+pol_sub+source+pos+gram+Doc2Vec+title]\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "\n",
    "stra = \"stratified\"\n",
    "feats = feats_com[1]\n",
    "\n",
    "X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "clf = DummyClassifier(strategy=stra, random_state=0)\n",
    "clf = clf.fit(X[:2758], y[:2758])\n",
    "y_probas = clf.predict_proba(X[2758:])\n",
    "predictions1 =  pd.DataFrame(y_probas,\n",
    "                            columns = \n",
    "                            ['idel_nlp','buy_nlp','sell_nlp'])\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "predictions1['true_value'] = true['true_value']\n",
    "predictions1.to_pickle('./Dummy/prediction_dummy_nlp1.pkl')\n",
    "\n",
    "\n",
    "feats = feats_com[1] + items['all_feats'][:189]\n",
    "X,y = get_data(df, feats, 'vb200_vf2_volatility_VWAP_200')\n",
    "clf = DummyClassifier(strategy=stra, random_state=0)\n",
    "clf = clf.fit(X[:2758], y[:2758])\n",
    "y_probas = clf.predict_proba(X[2758:])\n",
    "predictions2 =  pd.DataFrame(y_probas,\n",
    "                            columns = \n",
    "                            ['idel_all','buy_all','sell_all'])\n",
    "true = pd.DataFrame(y[2758:],columns = ['true_value'])\n",
    "predictions2['true_value'] = true['true_value']\n",
    "predictions2.to_pickle('./Dummy/prediction_dummy_all1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4WmnkFXK7RfD"
   ],
   "name": "03b3_ RUC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
